[
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Making Backyards Affordable for All",
    "section": "",
    "text": "Show/Hide Code\nif(!dir.exists(file.path(\"data\", \"mp02\"))){\n    dir.create(file.path(\"data\", \"mp02\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nlibrary &lt;- function(pkg){\n    ## Mask base::library() to automatically install packages if needed\n    ## Masking is important here so downlit picks up packages and links\n    ## to documentation\n    pkg &lt;- as.character(substitute(pkg))\n    options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n    if(!require(pkg, character.only=TRUE, quietly=TRUE)) install.packages(pkg)\n    stopifnot(require(pkg, character.only=TRUE, quietly=TRUE))\n}\n\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(readxl)\nlibrary(tidycensus)\n\nget_acs_all_years &lt;- function(variable, geography=\"cbsa\",\n                              start_year=2009, end_year=2023){\n    fname &lt;- glue(\"{variable}_{geography}_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        YEARS &lt;- seq(start_year, end_year)\n        YEARS &lt;- YEARS[YEARS != 2020] # Drop 2020 - No survey (covid)\n        \n        ALL_DATA &lt;- map(YEARS, function(yy){\n            tidycensus::get_acs(geography, variable, year=yy, survey=\"acs1\") |&gt;\n                mutate(year=yy) |&gt;\n                select(-moe, -variable) |&gt;\n                rename(!!variable := estimate)\n        }) |&gt; bind_rows()\n        \n        write_csv(ALL_DATA, fname)\n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\n# Household income (12 month)\nINCOME &lt;- get_acs_all_years(\"B19013_001\") |&gt;\n    rename(household_income = B19013_001)\n\n# Monthly rent\nRENT &lt;- get_acs_all_years(\"B25064_001\") |&gt;\n    rename(monthly_rent = B25064_001)\n\n# Total population\nPOPULATION &lt;- get_acs_all_years(\"B01003_001\") |&gt;\n    rename(population = B01003_001)\n\n# Total number of households\nHOUSEHOLDS &lt;- get_acs_all_years(\"B11001_001\") |&gt;\n    rename(households = B11001_001)\n\n\n\n\nShow/Hide Code\nget_building_permits &lt;- function(start_year = 2009, end_year = 2023){\n    fname &lt;- glue(\"housing_units_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        HISTORICAL_YEARS &lt;- seq(start_year, 2018)\n        \n        HISTORICAL_DATA &lt;- map(HISTORICAL_YEARS, function(yy){\n            historical_url &lt;- glue(\"https://www.census.gov/construction/bps/txt/tb3u{yy}.txt\")\n                \n            LINES &lt;- readLines(historical_url)[-c(1:11)]\n\n            CBSA_LINES &lt;- str_detect(LINES, \"^[[:digit:]]\")\n            CBSA &lt;- as.integer(str_sub(LINES[CBSA_LINES], 5, 10))\n\n            PERMIT_LINES &lt;- str_detect(str_sub(LINES, 48, 53), \"[[:digit:]]\")\n            PERMITS &lt;- as.integer(str_sub(LINES[PERMIT_LINES], 48, 53))\n            \n            data_frame(CBSA = CBSA,\n                       new_housing_units_permitted = PERMITS, \n                       year = yy)\n        }) |&gt; bind_rows()\n        \n        CURRENT_YEARS &lt;- seq(2019, end_year)\n        \n        CURRENT_DATA &lt;- map(CURRENT_YEARS, function(yy){\n            current_url &lt;- glue(\"https://www.census.gov/construction/bps/xls/msaannual_{yy}99.xls\")\n            \n            temp &lt;- tempfile()\n            \n            download.file(current_url, destfile = temp, mode=\"wb\")\n            \n            fallback &lt;- function(.f1, .f2){\n                function(...){\n                    tryCatch(.f1(...), \n                             error=function(e) .f2(...))\n                }\n            }\n            \n            reader &lt;- fallback(read_xlsx, read_xls)\n            \n            reader(temp, skip=5) |&gt;\n                na.omit() |&gt;\n                select(CBSA, Total) |&gt;\n                mutate(year = yy) |&gt;\n                rename(new_housing_units_permitted = Total)\n        }) |&gt; bind_rows()\n        \n        ALL_DATA &lt;- rbind(HISTORICAL_DATA, CURRENT_DATA)\n        \n        write_csv(ALL_DATA, fname)\n        \n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\nPERMITS &lt;- get_building_permits()\n\n\n\n\nShow/Hide Code\nlibrary(httr2)\nlibrary(rvest)\nget_bls_industry_codes &lt;- function(){\n    fname &lt;- fname &lt;- file.path(\"data\", \"mp02\", \"bls_industry_codes.csv\")\n    \n    if(!file.exists(fname)){\n    \n        resp &lt;- request(\"https://www.bls.gov\") |&gt; \n            req_url_path(\"cew\", \"classifications\", \"industry\", \"industry-titles.htm\") |&gt;\n            req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n            req_error(is_error = \\(resp) FALSE) |&gt;\n            req_perform()\n        \n        resp_check_status(resp)\n        \n        naics_table &lt;- resp_body_html(resp) |&gt;\n            html_element(\"#naics_titles\") |&gt; \n            html_table() |&gt;\n            mutate(title = str_trim(str_remove(str_remove(`Industry Title`, Code), \"NAICS\"))) |&gt;\n            select(-`Industry Title`) |&gt;\n            mutate(depth = if_else(nchar(Code) &lt;= 5, nchar(Code) - 1, NA)) |&gt;\n            filter(!is.na(depth))\n        \n        naics_table &lt;- naics_table |&gt; \n            filter(depth == 4) |&gt; \n            rename(level4_title=title) |&gt; \n            mutate(level1_code = str_sub(Code, end=2), \n                   level2_code = str_sub(Code, end=3), \n                   level3_code = str_sub(Code, end=4)) |&gt;\n            left_join(naics_table, join_by(level1_code == Code)) |&gt;\n            rename(level1_title=title) |&gt;\n            left_join(naics_table, join_by(level2_code == Code)) |&gt;\n            rename(level2_title=title) |&gt;\n            left_join(naics_table, join_by(level3_code == Code)) |&gt;\n            rename(level3_title=title) |&gt;\n            select(-starts_with(\"depth\")) |&gt;\n            rename(level4_code = Code) |&gt;\n            select(level1_title, level2_title, level3_title, level4_title, \n                   level1_code,  level2_code,  level3_code,  level4_code)\n    \n        write_csv(naics_table, fname)\n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n    \n}\n\nINDUSTRY_CODES &lt;- get_bls_industry_codes()\n\n\n\n\nShow/Hide Code\nlibrary(httr2)\nlibrary(rvest)\nget_bls_qcew_annual_averages &lt;- function(start_year=2009, end_year=2023){\n    fname &lt;- glue(\"bls_qcew_{start_year}_{end_year}.csv.gz\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    YEARS &lt;- seq(start_year, end_year)\n    YEARS &lt;- YEARS[YEARS != 2020] # Drop Covid year to match ACS\n    \n    if(!file.exists(fname)){\n        ALL_DATA &lt;- map(YEARS, .progress=TRUE, possibly(function(yy){\n            fname_inner &lt;- file.path(\"data\", \"mp02\", glue(\"{yy}_qcew_annual_singlefile.zip\"))\n            \n            if(!file.exists(fname_inner)){\n                request(\"https://www.bls.gov\") |&gt; \n                    req_url_path(\"cew\", \"data\", \"files\", yy, \"csv\",\n                                 glue(\"{yy}_annual_singlefile.zip\")) |&gt;\n                    req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n                    req_retry(max_tries=5) |&gt;\n                    req_perform(fname_inner)\n            }\n            \n            if(file.info(fname_inner)$size &lt; 755e5){\n                warning(sQuote(fname_inner), \"appears corrupted. Please delete and retry this step.\")\n            }\n            \n            read_csv(fname_inner, \n                     show_col_types=FALSE) |&gt; \n                mutate(YEAR = yy) |&gt;\n                select(area_fips, \n                       industry_code, \n                       annual_avg_emplvl, \n                       total_annual_wages, \n                       YEAR) |&gt;\n                filter(nchar(industry_code) &lt;= 5, \n                       str_starts(area_fips, \"C\")) |&gt;\n                filter(str_detect(industry_code, \"-\", negate=TRUE)) |&gt;\n                mutate(FIPS = area_fips, \n                       INDUSTRY = as.integer(industry_code), \n                       EMPLOYMENT = as.integer(annual_avg_emplvl), \n                       TOTAL_WAGES = total_annual_wages) |&gt;\n                select(-area_fips, \n                       -industry_code, \n                       -annual_avg_emplvl, \n                       -total_annual_wages) |&gt;\n                # 10 is a special value: \"all industries\" , so omit\n                filter(INDUSTRY != 10) |&gt; \n                mutate(AVG_WAGE = TOTAL_WAGES / EMPLOYMENT)\n        })) |&gt; bind_rows()\n        \n        write_csv(ALL_DATA, fname)\n    }\n    \n    ALL_DATA &lt;- read_csv(fname, show_col_types=FALSE)\n    \n    ALL_DATA_YEARS &lt;- unique(ALL_DATA$YEAR)\n    \n    YEARS_DIFF &lt;- setdiff(YEARS, ALL_DATA_YEARS)\n    \n    if(length(YEARS_DIFF) &gt; 0){\n        stop(\"Download failed for the following years: \", YEARS_DIFF, \n             \". Please delete intermediate files and try again.\")\n    }\n    \n    ALL_DATA\n}\n\nWAGES &lt;- get_bls_qcew_annual_averages()"
  },
  {
    "objectID": "mp02.html#data-acquisition",
    "href": "mp02.html#data-acquisition",
    "title": "Making Backyards Affordable for All",
    "section": "",
    "text": "Show/Hide Code\nif(!dir.exists(file.path(\"data\", \"mp02\"))){\n    dir.create(file.path(\"data\", \"mp02\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nlibrary &lt;- function(pkg){\n    ## Mask base::library() to automatically install packages if needed\n    ## Masking is important here so downlit picks up packages and links\n    ## to documentation\n    pkg &lt;- as.character(substitute(pkg))\n    options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n    if(!require(pkg, character.only=TRUE, quietly=TRUE)) install.packages(pkg)\n    stopifnot(require(pkg, character.only=TRUE, quietly=TRUE))\n}\n\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(readxl)\nlibrary(tidycensus)\n\nget_acs_all_years &lt;- function(variable, geography=\"cbsa\",\n                              start_year=2009, end_year=2023){\n    fname &lt;- glue(\"{variable}_{geography}_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        YEARS &lt;- seq(start_year, end_year)\n        YEARS &lt;- YEARS[YEARS != 2020] # Drop 2020 - No survey (covid)\n        \n        ALL_DATA &lt;- map(YEARS, function(yy){\n            tidycensus::get_acs(geography, variable, year=yy, survey=\"acs1\") |&gt;\n                mutate(year=yy) |&gt;\n                select(-moe, -variable) |&gt;\n                rename(!!variable := estimate)\n        }) |&gt; bind_rows()\n        \n        write_csv(ALL_DATA, fname)\n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\n# Household income (12 month)\nINCOME &lt;- get_acs_all_years(\"B19013_001\") |&gt;\n    rename(household_income = B19013_001)\n\n# Monthly rent\nRENT &lt;- get_acs_all_years(\"B25064_001\") |&gt;\n    rename(monthly_rent = B25064_001)\n\n# Total population\nPOPULATION &lt;- get_acs_all_years(\"B01003_001\") |&gt;\n    rename(population = B01003_001)\n\n# Total number of households\nHOUSEHOLDS &lt;- get_acs_all_years(\"B11001_001\") |&gt;\n    rename(households = B11001_001)\n\n\n\n\nShow/Hide Code\nget_building_permits &lt;- function(start_year = 2009, end_year = 2023){\n    fname &lt;- glue(\"housing_units_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        HISTORICAL_YEARS &lt;- seq(start_year, 2018)\n        \n        HISTORICAL_DATA &lt;- map(HISTORICAL_YEARS, function(yy){\n            historical_url &lt;- glue(\"https://www.census.gov/construction/bps/txt/tb3u{yy}.txt\")\n                \n            LINES &lt;- readLines(historical_url)[-c(1:11)]\n\n            CBSA_LINES &lt;- str_detect(LINES, \"^[[:digit:]]\")\n            CBSA &lt;- as.integer(str_sub(LINES[CBSA_LINES], 5, 10))\n\n            PERMIT_LINES &lt;- str_detect(str_sub(LINES, 48, 53), \"[[:digit:]]\")\n            PERMITS &lt;- as.integer(str_sub(LINES[PERMIT_LINES], 48, 53))\n            \n            data_frame(CBSA = CBSA,\n                       new_housing_units_permitted = PERMITS, \n                       year = yy)\n        }) |&gt; bind_rows()\n        \n        CURRENT_YEARS &lt;- seq(2019, end_year)\n        \n        CURRENT_DATA &lt;- map(CURRENT_YEARS, function(yy){\n            current_url &lt;- glue(\"https://www.census.gov/construction/bps/xls/msaannual_{yy}99.xls\")\n            \n            temp &lt;- tempfile()\n            \n            download.file(current_url, destfile = temp, mode=\"wb\")\n            \n            fallback &lt;- function(.f1, .f2){\n                function(...){\n                    tryCatch(.f1(...), \n                             error=function(e) .f2(...))\n                }\n            }\n            \n            reader &lt;- fallback(read_xlsx, read_xls)\n            \n            reader(temp, skip=5) |&gt;\n                na.omit() |&gt;\n                select(CBSA, Total) |&gt;\n                mutate(year = yy) |&gt;\n                rename(new_housing_units_permitted = Total)\n        }) |&gt; bind_rows()\n        \n        ALL_DATA &lt;- rbind(HISTORICAL_DATA, CURRENT_DATA)\n        \n        write_csv(ALL_DATA, fname)\n        \n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\nPERMITS &lt;- get_building_permits()\n\n\n\n\nShow/Hide Code\nlibrary(httr2)\nlibrary(rvest)\nget_bls_industry_codes &lt;- function(){\n    fname &lt;- fname &lt;- file.path(\"data\", \"mp02\", \"bls_industry_codes.csv\")\n    \n    if(!file.exists(fname)){\n    \n        resp &lt;- request(\"https://www.bls.gov\") |&gt; \n            req_url_path(\"cew\", \"classifications\", \"industry\", \"industry-titles.htm\") |&gt;\n            req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n            req_error(is_error = \\(resp) FALSE) |&gt;\n            req_perform()\n        \n        resp_check_status(resp)\n        \n        naics_table &lt;- resp_body_html(resp) |&gt;\n            html_element(\"#naics_titles\") |&gt; \n            html_table() |&gt;\n            mutate(title = str_trim(str_remove(str_remove(`Industry Title`, Code), \"NAICS\"))) |&gt;\n            select(-`Industry Title`) |&gt;\n            mutate(depth = if_else(nchar(Code) &lt;= 5, nchar(Code) - 1, NA)) |&gt;\n            filter(!is.na(depth))\n        \n        naics_table &lt;- naics_table |&gt; \n            filter(depth == 4) |&gt; \n            rename(level4_title=title) |&gt; \n            mutate(level1_code = str_sub(Code, end=2), \n                   level2_code = str_sub(Code, end=3), \n                   level3_code = str_sub(Code, end=4)) |&gt;\n            left_join(naics_table, join_by(level1_code == Code)) |&gt;\n            rename(level1_title=title) |&gt;\n            left_join(naics_table, join_by(level2_code == Code)) |&gt;\n            rename(level2_title=title) |&gt;\n            left_join(naics_table, join_by(level3_code == Code)) |&gt;\n            rename(level3_title=title) |&gt;\n            select(-starts_with(\"depth\")) |&gt;\n            rename(level4_code = Code) |&gt;\n            select(level1_title, level2_title, level3_title, level4_title, \n                   level1_code,  level2_code,  level3_code,  level4_code)\n    \n        write_csv(naics_table, fname)\n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n    \n}\n\nINDUSTRY_CODES &lt;- get_bls_industry_codes()\n\n\n\n\nShow/Hide Code\nlibrary(httr2)\nlibrary(rvest)\nget_bls_qcew_annual_averages &lt;- function(start_year=2009, end_year=2023){\n    fname &lt;- glue(\"bls_qcew_{start_year}_{end_year}.csv.gz\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    YEARS &lt;- seq(start_year, end_year)\n    YEARS &lt;- YEARS[YEARS != 2020] # Drop Covid year to match ACS\n    \n    if(!file.exists(fname)){\n        ALL_DATA &lt;- map(YEARS, .progress=TRUE, possibly(function(yy){\n            fname_inner &lt;- file.path(\"data\", \"mp02\", glue(\"{yy}_qcew_annual_singlefile.zip\"))\n            \n            if(!file.exists(fname_inner)){\n                request(\"https://www.bls.gov\") |&gt; \n                    req_url_path(\"cew\", \"data\", \"files\", yy, \"csv\",\n                                 glue(\"{yy}_annual_singlefile.zip\")) |&gt;\n                    req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n                    req_retry(max_tries=5) |&gt;\n                    req_perform(fname_inner)\n            }\n            \n            if(file.info(fname_inner)$size &lt; 755e5){\n                warning(sQuote(fname_inner), \"appears corrupted. Please delete and retry this step.\")\n            }\n            \n            read_csv(fname_inner, \n                     show_col_types=FALSE) |&gt; \n                mutate(YEAR = yy) |&gt;\n                select(area_fips, \n                       industry_code, \n                       annual_avg_emplvl, \n                       total_annual_wages, \n                       YEAR) |&gt;\n                filter(nchar(industry_code) &lt;= 5, \n                       str_starts(area_fips, \"C\")) |&gt;\n                filter(str_detect(industry_code, \"-\", negate=TRUE)) |&gt;\n                mutate(FIPS = area_fips, \n                       INDUSTRY = as.integer(industry_code), \n                       EMPLOYMENT = as.integer(annual_avg_emplvl), \n                       TOTAL_WAGES = total_annual_wages) |&gt;\n                select(-area_fips, \n                       -industry_code, \n                       -annual_avg_emplvl, \n                       -total_annual_wages) |&gt;\n                # 10 is a special value: \"all industries\" , so omit\n                filter(INDUSTRY != 10) |&gt; \n                mutate(AVG_WAGE = TOTAL_WAGES / EMPLOYMENT)\n        })) |&gt; bind_rows()\n        \n        write_csv(ALL_DATA, fname)\n    }\n    \n    ALL_DATA &lt;- read_csv(fname, show_col_types=FALSE)\n    \n    ALL_DATA_YEARS &lt;- unique(ALL_DATA$YEAR)\n    \n    YEARS_DIFF &lt;- setdiff(YEARS, ALL_DATA_YEARS)\n    \n    if(length(YEARS_DIFF) &gt; 0){\n        stop(\"Download failed for the following years: \", YEARS_DIFF, \n             \". Please delete intermediate files and try again.\")\n    }\n    \n    ALL_DATA\n}\n\nWAGES &lt;- get_bls_qcew_annual_averages()"
  },
  {
    "objectID": "mp02.html#year-that-the-albuquerque-nm-cbsa-number-10740-permit-the-most-new-housing-units",
    "href": "mp02.html#year-that-the-albuquerque-nm-cbsa-number-10740-permit-the-most-new-housing-units",
    "title": "Making Backyards Affordable for All",
    "section": "Year that the Albuquerque, NM (CBSA Number 10740) permit the most new housing units",
    "text": "Year that the Albuquerque, NM (CBSA Number 10740) permit the most new housing units\n\n\nShow/Hide Code\nlibrary(dplyr)\n\n\nabq_years &lt;- PERMITS |&gt;\n  filter(CBSA == 10740) |&gt;\n  group_by(year) |&gt;\n  summarize(total_units = sum(new_housing_units_permitted, na.rm = TRUE)) |&gt;\n  arrange(desc(total_units)) ## Albuquerque (CBSA 10740): total permitted units by year\n\n\nabq_years |&gt; slice_head(n = 1) ## ( top year (may be a COVID artifact)\n\n\n# A tibble: 1 × 2\n   year total_units\n  &lt;dbl&gt;       &lt;dbl&gt;\n1  2021        4021\n\n\nShow/Hide Code\nabq_years |&gt; slice_head(n = 5) ## (B) Show the top 5 to inspect nearby values\n\n\n# A tibble: 5 × 2\n   year total_units\n  &lt;dbl&gt;       &lt;dbl&gt;\n1  2021        4021\n2  2022        2852\n3  2023        2834\n4  2013        2606\n5  2014        2543\n\n\nShow/Hide Code\nabq_pre_covid &lt;- abq_years |&gt;\n  filter(!year %in% c(2020, 2021)) |&gt;\n  slice_head(n = 1)\n\nabq_pre_covid ##     re-run excluding 2020–2021 (common pandemic reporting quirks)\n\n\n# A tibble: 1 × 2\n   year total_units\n  &lt;dbl&gt;       &lt;dbl&gt;\n1  2022        2852\n\n\nThey permitted the largest number of new housing units in 2022 (2,852 units). However, this spike likely reflects a COVID-19 reporting artifact, as permits delayed during 2020–2021 were recorded later."
  },
  {
    "objectID": "mp02.html#state-not-cbsa-which-had-the-highest-average-individual-income-in-2015",
    "href": "mp02.html#state-not-cbsa-which-had-the-highest-average-individual-income-in-2015",
    "title": "Making Backyards Affordable for All",
    "section": "State (not CBSA) Which had the highest average individual income in 2015",
    "text": "State (not CBSA) Which had the highest average individual income in 2015\n\n\nShow/Hide Code\nlibrary(dplyr)\nlibrary(stringr)\n\n\nincome_2015 &lt;- INCOME |&gt; filter(year == 2015)\nhouseholds_2015 &lt;- HOUSEHOLDS |&gt; filter(year == 2015)\npopulation_2015 &lt;- POPULATION |&gt; filter(year == 2015) ##Filter data to the year 2015\n\n\nincome_joined &lt;- income_2015 |&gt;\n  left_join(households_2015 |&gt; select(GEOID, households), by = \"GEOID\") |&gt;\n  left_join(population_2015 |&gt; select(GEOID, population), by = \"GEOID\") ##Join the datasets using GEOID (common CBSA identifier)\n\n\nincome_joined &lt;- income_joined |&gt;\n  mutate(total_income = household_income * households) ##Compute total income per CBSA\n\n\nincome_joined &lt;- income_joined |&gt;\n  mutate(state = str_extract(NAME, \", (.{2})\")) ##Extract state abbreviation from CBSA name\n\n\nstate_income &lt;- income_joined |&gt;\n  group_by(state) |&gt;\n  summarize(\n    total_income = sum(total_income, na.rm = TRUE),\n    total_population = sum(population, na.rm = TRUE),\n    avg_individual_income = total_income / total_population\n  ) |&gt;\n  arrange(desc(avg_individual_income)) ##  Compute totals by state\n\n\nstate_income |&gt; slice_head(n = 1) ## Display the top state\n\n\n# A tibble: 1 × 4\n  state total_income total_population avg_individual_income\n  &lt;chr&gt;        &lt;dbl&gt;            &lt;dbl&gt;                 &lt;dbl&gt;\n1 , DC  202663489140          6098283                33233.\n\n\nWhich was DC, with a total income of 202,663,489,140."
  },
  {
    "objectID": "mp02.html#ata-scientists-and-business-analysts-are-recorded-under-naics-code-5182.-the-last-year-in-which-the-nyc-cbsa-had-the-most-data-scientists-in-the-country",
    "href": "mp02.html#ata-scientists-and-business-analysts-are-recorded-under-naics-code-5182.-the-last-year-in-which-the-nyc-cbsa-had-the-most-data-scientists-in-the-country",
    "title": "Making Backyards Affordable for All",
    "section": "Ata scientists and business analysts are recorded under NAICS code 5182. The last year in which the NYC CBSA had the most data scientists in the country",
    "text": "Ata scientists and business analysts are recorded under NAICS code 5182. The last year in which the NYC CBSA had the most data scientists in the country\n\n\nShow/Hide Code\nlibrary(dplyr)\n\n\ndata_sci &lt;- WAGES %&gt;%\n  filter(INDUSTRY == 5182) #  data scientists and related occupations (NAICS 5182)\n\n\ntop_by_year &lt;- data_sci %&gt;%\n  group_by(YEAR, FIPS) %&gt;%\n  summarize(total_employment = sum(EMPLOYMENT, na.rm = TRUE)) %&gt;%\n  arrange(YEAR, desc(total_employment)) %&gt;%\n  group_by(YEAR) %&gt;%\n  slice_head(n = 1) # CBSA that had the highest employment each year\n\n\ntop_by_year\n\n\n# A tibble: 14 × 3\n# Groups:   YEAR [14]\n    YEAR FIPS  total_employment\n   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1  2009 C3562            16349\n 2  2010 C1910            13238\n 3  2011 C1910            13283\n 4  2012 C3562            14423\n 5  2013 C3562            14251\n 6  2014 C3562            17828\n 7  2015 C3562            18922\n 8  2016 C4186            16369\n 9  2017 C4186            18089\n10  2018 C4186            22379\n11  2019 C4186            24154\n12  2021 C1206            15810\n13  2022 C4186            34080\n14  2023 C4186            32961\n\n\nShow/Hide Code\nnyc_last_year &lt;- top_by_year %&gt;%\n  filter(FIPS == 35620) %&gt;%\n  slice_tail(n = 1)\n\nnyc_last_year\n\n\n# A tibble: 0 × 3\n# Groups:   YEAR [0]\n# ℹ 3 variables: YEAR &lt;dbl&gt;, FIPS &lt;chr&gt;, total_employment &lt;dbl&gt;\n\n\nWhich was 2015. After 2015, the San Francisco–Oakland–Berkeley CBSA (C4186) surpassed New York in total data-science employment."
  },
  {
    "objectID": "mp02.html#the-relationship-between-monthly-rent-and-average-household-income-per-cbsa-in-2009.",
    "href": "mp02.html#the-relationship-between-monthly-rent-and-average-household-income-per-cbsa-in-2009.",
    "title": "Making Backyards Affordable for All",
    "section": "The relationship between monthly rent and average household income per CBSA in 2009.",
    "text": "The relationship between monthly rent and average household income per CBSA in 2009.\n\n\nShow/Hide Code\nlibrary(dplyr)\nlibrary(ggplot2) ###  The relationship between monthly rent and average household income per CBSA in 2009.\n\n\nincome_2009 &lt;- INCOME |&gt; filter(year == 2009)\nrent_2009   &lt;- RENT   |&gt; filter(year == 2009) # Filter for 2009\n\nrent_income_2009 &lt;- income_2009 |&gt;\n  left_join(rent_2009 |&gt; select(GEOID, monthly_rent), by = \"GEOID\") |&gt;\n  select(NAME, household_income, monthly_rent)\n  \nggplot(rent_income_2009, aes(x = household_income, y = monthly_rent)) +\n  geom_point(color = \"steelblue\", alpha = 0.7) +     # points for each CBSA\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +  # linear trend line\n  labs(\n    title = \"Relationship Between Monthly Rent and Household Income per CBSA (2009)\",\n    x = \"Average Household Income ($)\",\n    y = \"Average Monthly Rent ($)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe scatter plot shows a strong positive relationship between average household income and monthly rent across CBSAs in 2009. Areas with higher household incomes tend to have higher average rents, as indicated by the upward sloping linear trend line. This suggests that housing costs scale proportionally with income levels, reflecting higher demand and cost of living in wealthier regions."
  },
  {
    "objectID": "mp02.html#the-relationship-between-total-employment-and-total-employment-in-the-health-care-and-social-services-sector-naics-62-across-different-cbsas.",
    "href": "mp02.html#the-relationship-between-total-employment-and-total-employment-in-the-health-care-and-social-services-sector-naics-62-across-different-cbsas.",
    "title": "Making Backyards Affordable for All",
    "section": "The relationship between total employment and total employment in the health care and social services sector (NAICS 62) across different CBSAs.",
    "text": "The relationship between total employment and total employment in the health care and social services sector (NAICS 62) across different CBSAs.\n\n\nShow/Hide Code\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\ntotal_emp &lt;- WAGES |&gt;\n  group_by(FIPS, YEAR) |&gt;\n  summarize(total_employment = sum(EMPLOYMENT, na.rm = TRUE), .groups = \"drop\") # Total employment per CBSA per year (all industries)\n\n\nhealth_emp &lt;- WAGES |&gt;\n  filter(INDUSTRY == 62) |&gt;\n  group_by(FIPS, YEAR) |&gt;\n  summarize(health_employment = sum(EMPLOYMENT, na.rm = TRUE), .groups = \"drop\") # Health care (NAICS 62) employment per CBSA per year\n\n\nemployment_combined &lt;- total_emp |&gt;\n  left_join(health_emp, by = c(\"FIPS\", \"YEAR\")) |&gt;\n  mutate(health_employment = replace_na(health_employment, 0)) # Merge both datasets \n\nggplot(employment_combined, aes(x = total_employment, y = health_employment, color = as.factor(YEAR))) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +\n  labs(\n    title = \"Relationship Between Total Employment and Health Care Employment (NAICS 62) Across CBSAs\",\n    x = \"Total Employment\",\n    y = \"Employment in Health Care and Social Services\",\n    color = \"Year\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe scatter plot illustrates a strong positive relationship between total employment and employment in the health care and social services sector across CBSAs. As total employment increases, health sector employment also rises proportionally, indicating that larger labor markets sustain larger health care workforces."
  },
  {
    "objectID": "mp02.html#the-evolution-of-average-household-size-over-time.",
    "href": "mp02.html#the-evolution-of-average-household-size-over-time.",
    "title": "Making Backyards Affordable for All",
    "section": "The evolution of average household size over time.",
    "text": "The evolution of average household size over time.\n\n\nShow/Hide Code\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\nhousehold_size &lt;- HOUSEHOLDS |&gt;\n  left_join(POPULATION |&gt; select(GEOID, year, population),\n            by = c(\"GEOID\", \"year\")) |&gt;\n  mutate(avg_household_size = population / households) #  average household size per CBSA per year\nggplot(household_size, aes(x = year, y = avg_household_size, group = GEOID)) +\n  geom_line(alpha = 0.3, color = \"steelblue\") +\n  labs(\n    title = \"Evolution of Average Household Size Over Time\",\n    x = \"Year\",\n    y = \"Average Household Size\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe line plot shows the evolution of average household size across all CBSAs from 2009 to 2023. The trends indicate that household sizes have remained relatively stable nationwide, typically ranging between 2.5 and 3.0 persons per household. While a few metropolitan areas show small fluctuations or gradual increases, the overall pattern suggests minimal change in household composition over time."
  },
  {
    "objectID": "mp02.html#the-relationship-between-monthly-rent-and-average-household-income-per-cbsa-in-2009.-1",
    "href": "mp02.html#the-relationship-between-monthly-rent-and-average-household-income-per-cbsa-in-2009.-1",
    "title": "Making Backyards Affordable for All",
    "section": "The relationship between monthly rent and average household income per CBSA in 2009.",
    "text": "The relationship between monthly rent and average household income per CBSA in 2009.\n\n\nShow/Hide Code\nlibrary(dplyr)\nlibrary(ggplot2)\nrent_income_2009 &lt;- RENT |&gt; \n  filter(year == 2009) |&gt;\n  left_join(INCOME |&gt; filter(year == 2009) |&gt; select(GEOID, household_income),\n            by = \"GEOID\") # Filter for 2009 and join rent + income\n\nggplot(rent_income_2009, aes(x = household_income, y = monthly_rent)) +\n  geom_point(alpha = 0.6, color = \"steelblue\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\", linewidth = 1.2) +\n  labs(\n    title = \"Relationship Between Monthly Rent and Average Household Income (2009)\",\n    x = \"Average Household Income ($)\",\n    y = \"Average Monthly Rent ($)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe scatter plot above displays the relationship between average household income and monthly rent across CBSAs in 2009. Each point represents a metropolitan area, and the red line shows the linear trend between the two variables. There is a clear positive relationship: CBSAs with higher household incomes tend to have higher average monthly rents. This pattern suggests that housing costs scale with income levels, reflecting the higher demand and living costs typically found in wealthier regions."
  },
  {
    "objectID": "mp02.html#the-relationship-between-total-employment-and-total-employment-in-the-health-care-and-social-services-sector-naics-62-across-different-cbsas.-1",
    "href": "mp02.html#the-relationship-between-total-employment-and-total-employment-in-the-health-care-and-social-services-sector-naics-62-across-different-cbsas.-1",
    "title": "Making Backyards Affordable for All",
    "section": "The relationship between total employment and total employment in the health care and social services sector (NAICS 62) across different CBSAs.",
    "text": "The relationship between total employment and total employment in the health care and social services sector (NAICS 62) across different CBSAs.\n\n\nShow/Hide Code\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\nhealth_employment &lt;- WAGES |&gt;\n  filter(INDUSTRY == 62) |&gt;\n  group_by(YEAR, FIPS) |&gt;\n  summarize(health_employment = sum(EMPLOYMENT, na.rm = TRUE)) |&gt; \n  ungroup() # health care and social services industry (NAICS 62)\n\ntotal_employment &lt;- WAGES |&gt;\n  group_by(YEAR, FIPS) |&gt;\n  summarize(total_employment = sum(EMPLOYMENT, na.rm = TRUE)) |&gt;\n  ungroup()  #  total employment by CBSA and year\n\n\nemployment_joined &lt;- left_join(total_employment, health_employment, by = c(\"YEAR\", \"FIPS\")) # Merge the two datasets\n\n\nggplot(employment_joined, aes(x = total_employment, y = health_employment, color = as.factor(YEAR))) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +\n  labs(\n    title = \"Relationship Between Total Employment and Employment in Health Care & Social Services\",\n    x = \"Total Employment\",\n    y = \"Employment in Health Care and Social Services\",\n    color = \"Year\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe scatter plot above shows a positive relationship between total employment and employment in the health care and social services sector (NAICS 62) across CBSAs. Larger labor markets consistently employ more people in health care, reflecting the sector’s critical role in urban economies. The colors represent different years, showing how this relationship has evolved over time. The upward shift in later years suggests that employment in health care has grown faster than total employment, highlighting the sector’s steady expansion and increasing economic significance across the country."
  },
  {
    "objectID": "mp02.html#the-evolution-of-average-household-size-over-time.-1",
    "href": "mp02.html#the-evolution-of-average-household-size-over-time.-1",
    "title": "Making Backyards Affordable for All",
    "section": "The evolution of average household size over time.",
    "text": "The evolution of average household size over time.\n\n\nShow/Hide Code\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\navg_household_size &lt;- POPULATION |&gt;\n  left_join(HOUSEHOLDS, by = c(\"GEOID\", \"year\", \"NAME\")) |&gt;\n  mutate(avg_household_size = population / households) |&gt;\n  select(GEOID, NAME, year, avg_household_size) #  average household size per CBSA per year\n  \nggplot(avg_household_size, aes(x = year, y = avg_household_size, group = NAME)) +\n  geom_line(alpha = 0.3, color = \"steelblue\") +\n  labs(\n    title = \"Evolution of Average Household Size Over Time\",\n    x = \"Year\",\n    y = \"Average Household Size\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe line chart illustrates the evolution of average household size across CBSAs from 2009 to 2023. Each line represents a different metropolitan area, showing how household size varies regionally and over time. Overall, household size remains relatively stable, with most CBSAs clustered between 2.4 and 3.0 people per household. While some areas show slight increases or decreases, there is no significant long-term trend, indicating that household composition across the United States has remained largely consistent over the past decade."
  },
  {
    "objectID": "mp02.html#baseline-value-around-which-the-metric-is-centered.",
    "href": "mp02.html#baseline-value-around-which-the-metric-is-centered.",
    "title": "Making Backyards Affordable for All",
    "section": "Baseline value around which the metric is centered.",
    "text": "Baseline value around which the metric is centered.\n\n\nShow/Hide Code\nlibrary(dplyr)\n\nINCOME_clean &lt;- INCOME |&gt;\n  rename(MedianIncome = household_income)\n\nRENT_clean &lt;- RENT |&gt;\n  rename(MedianRent = monthly_rent)\n\ndata_joined &lt;- INCOME_clean |&gt;\n  inner_join(RENT_clean, by = c(\"GEOID\", \"year\")) # Joining both tables\n  \ndata_joined &lt;- data_joined |&gt;\n  mutate(rent_burden = (MedianRent * 12 / MedianIncome) * 100) # conversion monthly rent into annual rent\n  \nfirst_year &lt;- min(data_joined$year, na.rm = TRUE) # first year of the study\n\nbaseline_avg &lt;- data_joined |&gt;\n  filter(year == first_year) |&gt;\n  summarise(avg_burden = mean(rent_burden, na.rm = TRUE)) |&gt;\n  pull(avg_burden) # National average rent in burden in that first year\n  \ndata_joined &lt;- data_joined |&gt;\n  mutate(rent_burden_index = (rent_burden / baseline_avg) * 100) # Standarize 100 average rent burden in first year\nhead(data_joined)\n\n\n# A tibble: 6 × 8\n  GEOID NAME.x                  MedianIncome  year NAME.y MedianRent rent_burden\n  &lt;dbl&gt; &lt;chr&gt;                          &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 10140 Aberdeen, WA Micro Area        36345  2009 Aberd…        650        21.5\n2 10180 Abilene, TX Metro Area         42931  2009 Abile…        712        19.9\n3 10300 Adrian, MI Micro Area          45640  2009 Adria…        645        17.0\n4 10380 Aguadilla-Isabela-San …        13470  2009 Aguad…        363        32.3\n5 10420 Akron, OH Metro Area           47482  2009 Akron…        723        18.3\n6 10500 Albany, GA Metro Area          36218  2009 Alban…        624        20.7\n# ℹ 1 more variable: rent_burden_index &lt;dbl&gt;\n\n\nBaseline average rent burden = 19.40% First year = 2009 In 2009, the average U.S. resident spent about 19.4% of their income on rent."
  },
  {
    "objectID": "mp02.html#standardizing-my-metric-to-increase-interpretability.",
    "href": "mp02.html#standardizing-my-metric-to-increase-interpretability.",
    "title": "Making Backyards Affordable for All",
    "section": "Standardizing my metric to increase interpretability.",
    "text": "Standardizing my metric to increase interpretability.\n\n\nShow/Hide Code\ndata_joined &lt;- data_joined |&gt;\n  mutate(rent_burden = (MedianRent * 12 / MedianIncome) * 100) # rent burden (% of income spent on rent) \n\nbaseline_value &lt;- 19.4035977313493 # Set baseline from earlier calculation (19.4%) \n\n\ndata_joined &lt;- data_joined |&gt;\n  mutate(rent_burden_relative = rent_burden / baseline_value)  \n  # Compute rent burden relative to the 2009 national average\n\n\ndata_joined &lt;- data_joined |&gt;\n  mutate(\n    rent_burden_relative = rent_burden / baseline_value\n  )\ndata_joined &lt;- data_joined |&gt;\n  mutate(rent_burden = (MedianRent * 12 / MedianIncome) * 100,\n         rent_burden_relative = rent_burden / 19.4035977313493)  # 2009 baseline\n\nhead(data_joined,10)\n\n\n# A tibble: 10 × 9\n   GEOID NAME.x                 MedianIncome  year NAME.y MedianRent rent_burden\n   &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 10140 Aberdeen, WA Micro Ar…        36345  2009 Aberd…        650        21.5\n 2 10180 Abilene, TX Metro Area        42931  2009 Abile…        712        19.9\n 3 10300 Adrian, MI Micro Area         45640  2009 Adria…        645        17.0\n 4 10380 Aguadilla-Isabela-San…        13470  2009 Aguad…        363        32.3\n 5 10420 Akron, OH Metro Area          47482  2009 Akron…        723        18.3\n 6 10500 Albany, GA Metro Area         36218  2009 Alban…        624        20.7\n 7 10540 Albany-Lebanon, OR Mi…        47669  2009 Alban…        761        19.2\n 8 10580 Albany-Schenectady-Tr…        57677  2009 Alban…        833        17.3\n 9 10700 Albertville, AL Micro…        37284  2009 Alber…        579        18.6\n10 10740 Albuquerque, NM Metro…        46824  2009 Albuq…        726        18.6\n# ℹ 2 more variables: rent_burden_index &lt;dbl&gt;, rent_burden_relative &lt;dbl&gt;\n\n\nShow/Hide Code\nlibrary(DT)\nnyc_burden &lt;- data_joined |&gt;\n  filter(str_detect(NAME.x, \"New York\")) |&gt;\n  select(NAME.x, year, MedianIncome, MedianRent, rent_burden, rent_burden_relative) |&gt;\n  arrange(year) # New York metropolitan area\n \ndatatable(\n  nyc_burden,\n  caption = \"Rent Burden Over Time in the New York–Newark–Jersey City Metropolitan Area\",\n  options = list(pageLength = 15, autoWidth = TRUE),\n  rownames = FALSE\n) # Table for New York\n\n\n\n\n\n\nShow/Hide Code\nlibrary(ggplot2)\n\nggplot(nyc_burden, aes(x = year, y = rent_burden_relative)) +\n  geom_line(color = \"steelblue\", linewidth = 1.2) +\n  geom_point(color = \"darkblue\") +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Change in Rent Burden Over Time (New York Metro)\",\n    x = \"Year\",\n    y = \"Rent Burden (× 2009 Baseline)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow/Hide Code\nlibrary(DT)\n\ndatatable(\n  nyc_burden,\n  caption = \"Rent Burden Over Time in the New York–Newark–Jersey City Metropolitan Area\",\n  options = list(pageLength = 15, autoWidth = TRUE),\n  rownames = FALSE\n)\n\n\n\n\n\n\nShow/Hide Code\nlatest_year &lt;- max(data_joined$year, na.rm = TRUE) #  the latest year in your dataset\n\n\ntop_bottom &lt;- data_joined |&gt;\n  filter(year == latest_year) |&gt;\n  select(NAME.x, year, rent_burden, rent_burden_relative) |&gt;\n  arrange(desc(rent_burden))\n\nhighest_10 &lt;- top_bottom |&gt; slice_head(n = 10)\nlowest_10  &lt;- top_bottom |&gt; slice_tail(n = 10)  # top and bottom 10 CBSAs by rent burden\n\n\ndatatable(\n  highest_10,\n  caption = paste(\"Top 10 Metro Areas with Highest Rent Burden (\", latest_year, \")\", sep = \"\"),\n  options = list(pageLength = 10, autoWidth = TRUE),\n  rownames = FALSE\n) # Highest 10\n\n\n\n\n\n\nShow/Hide Code\ndatatable(\n  lowest_10,\n  caption = paste(\"Top 10 Metro Areas with Lowest Rent Burden (\", latest_year, \")\", sep = \"\"),\n  options = list(pageLength = 10, autoWidth = TRUE),\n  rownames = FALSE\n) # Lowest 10\n\n\n\n\n\n\nThe rent burden metric that I created shows clear differences in housing affordability across metropolitan areas in the United States. In the New York–Newark–Jersey City metro area, the rent burden stayed consistently between 1.10× and 1.18× the 2009 baseline, which means that residents continue to face significant affordability challenges. On the other hand, metros with the lowest rent burdens, such as Albertville, AL and Mount Airy, NC, have values closer to 0.7× the national baseline, showing that housing costs are much lower compared to income levels. This contrast emphasizes the uneven distribution of housing pressures nationwide and supports the idea that YIMBY-style housing policies are needed to increase supply and improve affordability in high-demand regions."
  },
  {
    "objectID": "mp02.html#housing-growth",
    "href": "mp02.html#housing-growth",
    "title": "Making Backyards Affordable for All",
    "section": "Housing Growth",
    "text": "Housing Growth\n\n\nShow/Hide Code\nlibrary(dplyr)\n\npop_permits &lt;- POPULATION |&gt;\n  inner_join(PERMITS, by = c(\"GEOID\" = \"CBSA\", \"year\")) |&gt;\n  select(GEOID, NAME, year, population, new_housing_units_permitted) # jOIN BOTH DATASETS \n\npop_permits &lt;- pop_permits |&gt;\n  group_by(GEOID) |&gt;\n  arrange(year) |&gt;\n  mutate(\n    pop_lag5 = lag(population, 5),\n    pop_growth_5yr = population - pop_lag5\n  ) |&gt;\n  ungroup() # population growth over a rolling 5-year\n\npop_permits &lt;- pop_permits |&gt;\n  mutate(\n    housing_growth_instant = (new_housing_units_permitted / population) * 1000\n  ) # Two housing growth metrics\n  \npop_permits &lt;- pop_permits |&gt;\n  mutate(\n    housing_growth_rate = new_housing_units_permitted / pop_growth_5yr\n  ) # Rate based housing growth\n\npop_permits &lt;- pop_permits |&gt;\n  mutate(\n    inst_scaled = (housing_growth_instant - min(housing_growth_instant, na.rm = TRUE)) /\n                  (max(housing_growth_instant, na.rm = TRUE) - min(housing_growth_instant, na.rm = TRUE)) * 100,\n    rate_scaled = (housing_growth_rate - min(housing_growth_rate, na.rm = TRUE)) /\n                  (max(housing_growth_rate, na.rm = TRUE) - min(housing_growth_rate, na.rm = TRUE)) * 100\n  ) #Standardize and baseline metrics\n\npop_permits &lt;- pop_permits |&gt;\n  mutate(\n    composite_growth_index = (inst_scaled + rate_scaled) / 2\n  ) # composite housing growth score\n\nlibrary(DT)\n\nlatest_year &lt;- max(pop_permits$year, na.rm = TRUE)\n\ninst_rank &lt;- pop_permits |&gt;\n  filter(year == latest_year) |&gt;\n  select(NAME, year, housing_growth_instant, inst_scaled) |&gt;\n  arrange(desc(inst_scaled))\n\ndatatable(\n  inst_rank |&gt; slice_head(n = 10),\n  caption = paste(\"Top 10 Metro Areas – Instantaneous Housing Growth (\", latest_year, \")\", sep = \"\"),\n  options = list(pageLength = 10, autoWidth = TRUE),\n  rownames = FALSE\n)\n\n\n\n\n\n\nShow/Hide Code\ndatatable(\n  inst_rank |&gt; slice_tail(n = 10),\n  caption = paste(\"Bottom 10 Metro Areas – Instantaneous Housing Growth (\", latest_year, \")\", sep = \"\"),\n  options = list(pageLength = 10, autoWidth = TRUE),\n  rownames = FALSE\n) # Instantaneous growth\n\n\n\n\n\n\nShow/Hide Code\nrate_rank &lt;- pop_permits |&gt;\n  filter(year == latest_year) |&gt;\n  select(NAME, year, housing_growth_rate, rate_scaled) |&gt;\n  arrange(desc(rate_scaled))\n\ndatatable(\n  rate_rank |&gt; slice_head(n = 10),\n  caption = paste(\"Top 10 Metro Areas – Rate-Based Housing Growth (\", latest_year, \")\", sep = \"\"),\n  options = list(pageLength = 10, autoWidth = TRUE),\n  rownames = FALSE\n)\n\n\n\n\n\n\nShow/Hide Code\ndatatable(\n  rate_rank |&gt; slice_tail(n = 10),\n  caption = paste(\"Bottom 10 Metro Areas – Rate-Based Housing Growth (\", latest_year, \")\", sep = \"\"),\n  options = list(pageLength = 10, autoWidth = TRUE),\n  rownames = FALSE\n) # Rate based growth\n\n\n\n\n\n\nShow/Hide Code\ncomp_rank &lt;- pop_permits |&gt;\n  filter(year == latest_year) |&gt;\n  select(NAME, year, inst_scaled, rate_scaled, composite_growth_index) |&gt;\n  arrange(desc(composite_growth_index))\n\ndatatable(\n  comp_rank |&gt; slice_head(n = 10),\n  caption = paste(\"Top 10 Metro Areas – Composite Housing Growth Index (\", latest_year, \")\", sep = \"\"),\n  options = list(pageLength = 10, autoWidth = TRUE),\n  rownames = FALSE\n)\n\n\n\n\n\n\nShow/Hide Code\ndatatable(\n  comp_rank |&gt; slice_tail(n = 10),\n  caption = paste(\"Bottom 10 Metro Areas – Composite Housing Growth Index (\", latest_year, \")\", sep = \"\"),\n  options = list(pageLength = 10, autoWidth = TRUE),\n  rownames = FALSE\n) # composite growth score\n\n\n\n\n\n\nTaken together, the rent burden and housing growth metrics paint a clear picture of the U.S. housing landscape. High-demand metros like New York and Florida regions face strong affordability pressures but mixed construction responses. Meanwhile, smaller metros in the South and Midwest show lower rent burdens and higher relative building activity. The composite index highlights metros effectively balancing population and housing growth, key evidence for promoting YIMBY-style zoning reforms to encourage more housing development in constrained markets.\nThe metros with the lowest composite housing growth scores (including Johnstown, PA, Decatur, IL, and Weirton–Steubenville, WV–OH) exhibit particularly weak housing supply responses. These regions permit very few new units relative to both population size and growth. Although some of these areas are not experiencing extreme affordability crises, their lack of development reflects deeper structural barriers to growth. YIMBY-oriented federal incentives could help such areas revitalize local housing markets, attract new residents, and improve overall economic resilience."
  },
  {
    "objectID": "mp02.html#visualization",
    "href": "mp02.html#visualization",
    "title": "Making Backyards Affordable for All",
    "section": "VISUALIZATION",
    "text": "VISUALIZATION\nI examined the relationship between rent burden and housing growth using CBSA-level data. A CBSA was classified as YIMBY if it had high early rent burden, decreasing rent burden over time, positive population growth, and above-average housing growth.\n\n\nShow/Hide Code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(stringr)\nlibrary(ggrepel)\n\n\ndf &lt;- pop_permits %&gt;%\n  left_join(RENT_clean, by = c(\"GEOID\", \"NAME\", \"year\")) %&gt;%\n  rename(\n    cbsa = NAME,\n    rent_burden = MedianRent,              # Median rent proxy\n    population = population,               # population size\n    housing_units = new_housing_units_permitted # new housing permits\n  )\n\n\nif (max(df$rent_burden, na.rm = TRUE) &gt; 1.5) {\n  df &lt;- df %&gt;% mutate(rent_burden = rent_burden / 100)\n}\n\n \ndf_bounds &lt;- df %&gt;%\n  group_by(cbsa) %&gt;%\n  summarize(\n    year_first = min(year, na.rm = TRUE),\n    year_last  = max(year, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nsnapshots &lt;- df %&gt;%\n  inner_join(df_bounds, by = \"cbsa\") %&gt;%\n  mutate(tag = case_when(\n    year == year_first ~ \"first\",\n    year == year_last  ~ \"last\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(tag)) %&gt;%\n  select(cbsa, tag, year, rent_burden, population, housing_units) %&gt;%\n  pivot_wider(\n    names_from = tag,\n    values_from = c(year, rent_burden, population, housing_units),\n    names_sep = \"_\"\n  ) #   first/last years per CBSA \n\n\nmetrics &lt;- snapshots %&gt;%\n  mutate(\n    rb_early = rent_burden_first,\n    rb_change = rent_burden_last - rent_burden_first,\n    pop_growth_pct = (population_last - population_first) / population_first,\n    years_span = year_last - year_first,\n    housing_cagr = ifelse(\n      years_span &gt; 0 & housing_units_first &gt; 0,\n      (housing_units_last / housing_units_first)^(1 / years_span) - 1,\n      NA_real_\n    )\n  ) #  growth metrics \n\n \nrb_early_median  &lt;- median(metrics$rb_early, na.rm = TRUE)\nhousing_cagr_mean &lt;- mean(metrics$housing_cagr, na.rm = TRUE)\n\nclassified &lt;- metrics %&gt;%\n  mutate(\n    high_rb_early     = rb_early &gt;= rb_early_median,\n    rb_decreased      = rb_change &lt; 0,\n    pop_grew          = pop_growth_pct &gt; 0,\n    housing_above_avg = housing_cagr &gt;= housing_cagr_mean,\n    is_yimby = high_rb_early & rb_decreased & pop_grew & housing_above_avg\n  ) #   YIMBY CBSAs \n\n\nclassified %&gt;%\n  filter(is_yimby) %&gt;%\n  select(cbsa, rb_early, rb_change, pop_growth_pct, housing_cagr) #  identified YIMBY CBSAs \n\n\n# A tibble: 2 × 5\n  cbsa                            rb_early rb_change pop_growth_pct housing_cagr\n  &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1 Las Vegas-Paradise, NV Metro A…     10.3    -0.600         0.0515       0.0904\n2 Palm Coast, FL Metro Area           10.7    -1.28          0.0735       0.131 \n\n\n\n\nShow/Hide Code\nggplot(df, aes(x = year, y = rent_burden, group = cbsa)) +\n  geom_line(color = \"gray80\", linewidth = 0.4, alpha = 0.6) +\n\n  # Highlight YIMBY CBSAs\n  geom_line(\n    data = df %&gt;% semi_join(classified %&gt;% filter(is_yimby), by = \"cbsa\"),\n    aes(group = cbsa),\n    linewidth = 1.3,\n    color = \"#0072B2\"\n  ) +\n\n  # Label YIMBY CBSAs\n  geom_text_repel(\n    data = df %&gt;%\n      semi_join(classified %&gt;% filter(is_yimby), by = \"cbsa\") %&gt;%\n      group_by(cbsa) %&gt;% filter(year == max(year)) %&gt;% ungroup(),\n    aes(label = cbsa),\n    size = 3.5,\n    nudge_x = 0.4,\n    direction = \"y\",\n    segment.color = \"gray50\",\n    segment.size = 0.3\n  ) +\n  labs(\n    title = \"Median Rent Over Time by CBSA\",\n    subtitle = \"Highlighted CBSAs show YIMBY success (rent ↓ , population & housing ↑)\",\n    x = \"Year\", y = \"Median Rent ($)\"\n  ) +\n  scale_y_continuous(labels = dollar_format(accuracy = 1)) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    plot.title.position = \"plot\",\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank()\n  ) # Rent trend visualization\n\n\n\n\n\n\n\n\n\nShow/Hide Code\nggsave(\"YIMBY_rent_trend.png\", width = 8, height = 6, dpi = 300)\n\n\nLas Vegas–Paradise and Palm Coast stand out visually. Their rent burden trends slightly downward while most CBSAs trend upward — supporting your argument.\n\n\nShow/Hide Code\nclassified_adj &lt;- classified %&gt;%\n  filter(\n    housing_cagr &gt; -0.05 & housing_cagr &lt; 0.05,   # ±5 % housing growth\n    rb_change &gt; -5 & rb_change &lt; 15               # filter out extreme rent spikes\n  )\n\nhousing_cagr_mean &lt;- mean(classified_adj$housing_cagr, na.rm = TRUE)\n\nggplot(classified_adj, aes(x = housing_cagr, y = rb_change)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray40\") +\n  geom_vline(xintercept = housing_cagr_mean, linetype = \"dashed\", color = \"gray40\") +\n  geom_point(aes(size = pop_growth_pct), color = \"gray70\", alpha = 0.6) +\n  geom_point(\n    data = classified_adj %&gt;% filter(is_yimby),\n    aes(size = pop_growth_pct),\n    color = \"#0072B2\",\n    alpha = 0.9\n  ) +\n  geom_text_repel(\n    data = classified_adj %&gt;% filter(is_yimby),\n    aes(label = cbsa),\n    size = 3.2,\n    nudge_y = 0.4,\n    max.overlaps = 10\n  ) +\n  scale_x_continuous(\n    labels = percent_format(accuracy = 0.1),\n    limits = c(-0.05, 0.05),\n    breaks = seq(-0.05, 0.05, 0.01)\n  ) +\n  scale_y_continuous(labels = number_format(accuracy = 0.1)) +\n  scale_size_continuous(name = \"Population Growth (%)\", labels = percent) +\n  labs(\n    title = \"Housing Growth vs. Change in Rent Burden by CBSA\",\n    subtitle = \"Bottom-right quadrant = YIMBY success (housing ↑ , rent ↓)\",\n    x = \"Annual Housing Growth (CAGR)\",\n    y = \"Change in Median Rent ($)\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    plot.title.position = \"plot\",\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank()\n  ) #  Scatter visualization \n\n\n\n\n\n\n\n\n\nShow/Hide Code\nggsave(\"YIMBY_scatter_adjusted.png\", width = 8, height = 6, dpi = 300)\n\n\nBottom-right quadrant = YIMBY success zone rent decreased (y &lt; 0) housing growth above mean (x &gt; 0) Las Vegas–Paradise and Palm Coast appear here → strong YIMBY cases. Most CBSAs cluster around (0, 0), meaning stagnant housing and moderate rent increases."
  },
  {
    "objectID": "mp02.html#policy-brief",
    "href": "mp02.html#policy-brief",
    "title": "Making Backyards Affordable for All",
    "section": "Policy brief",
    "text": "Policy brief\nFederal “Build Homes Where People Need Them” Act\nMany metros face high rents because housing supply hasn’t kept up with population and jobs. My analysis of CBSAs (metro areas) identifies places where adding homes coincided with lower rent burden and continued population growth—a “YIMBY success.”\nPrimary sponsor: A representative from Las Vegas–Paradise, NV (YIMBY success in our study).\nStory: Started with relatively high rent burden, then rent burden fell while population and housing stock grew.\nCo-sponsor: A representative from New York–Newark–Jersey City, NY-NJ-PA (more NIMBY pattern).\nStory: High rents and slower housing growth make affordability gains difficult; this district would benefit from federal incentives to permit and build more homes.\nCoalition targets (two occupations with real presence in both metros)\nNurses & health-care support staff (hospitals, clinics, long-term care)\nWhy they care: Lower rents mean more take-home pay after housing, easier recruitment/retention for hospitals (less burnout from long commutes or relocating).\nHow the bill helps: Grants tied to local by-right approvals near medical campuses and transit reduce travel time and rent share, stabilizing staffing.\nConstruction trades (carpenters, electricians, plumbers, operating engineers)\nWhy they care: Predictable, faster approvals create steady job pipelines and apprenticeships.\nHow the bill helps: Funding is unlocked only when municipalities legalize enough homes, that means more projects and longer-run job security without boom-bust cycles.\nWhat the bill does (high level)\nPerformance-based grants to municipalities that adopt pro-housing policies (e.g., by-right multifamily near transit/job centers, gentle density in residential zones, streamlined approvals).\nHousing-linked infrastructure dollars (streets, sewers, schools, transit) released only when jurisdictions hit housing-production benchmarks.\nBonus points for projects that include workforce/teacher/nurse housing or that simplify code compliance for small infill builders.\nHow to explain the metrics\nRent burden: The share of typical renter income needed to pay rent. When this share falls over time especially in places that started high, that’s a strong affordability signal.\nHousing growth: The annual growth rate of the local housing stock (or sustained building permits). When housing grows faster than the metro average, supply is keeping up with demand.\nYIMBY success:\nHigh rent burden at the start, then it decreased;\nPopulation grew (city not shrinking); and\nHousing grew above average.\nTalking points the sponsors can use\nLas Vegas sponsor\nOur district proved that permitting and building more homes lowers rent burden without losing residents. This bill funds the playbook that already works here—so other cities can follow—and rewards us for continuing to permit responsibly.\nNew York co-sponsor\nOur constituents face persistently high rents and long commutes. This bill ties federal money to local reforms that unlock more homes near jobs and transit. It helps essential workers, nurses and teacher, and supports the building trades with steady work.\nElevator pitch\nThis bill delivers more homes, lower rent burden, and better worker retention by rewarding cities that actually permit and build. Pair a sponsor from a proven YIMBY success (Las Vegas) with a co-sponsor from a high-rent, housing-constrained metro (New York), and enlist nurses and the construction trades as visible champions. The metrics are simple, auditable, and fair—directing federal support where housing supply grows and rent burdens fall."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SILKSONG",
    "section": "",
    "text": "SILKSONG, (Hollow knight 2) has become one of the best games of 2025. \n\nLast Updated: Saturday 11 01, 2025 at 19:27PM"
  },
  {
    "objectID": "index.html#best-game-of-2025",
    "href": "index.html#best-game-of-2025",
    "title": "SILKSONG",
    "section": "",
    "text": "SILKSONG, (Hollow knight 2) has become one of the best games of 2025. \n\nLast Updated: Saturday 11 01, 2025 at 19:27PM"
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Top 10 Netflix Films/Shows",
    "section": "",
    "text": "show/hide code\nif(!dir.exists(file.path(\"data\", \"mp01\"))){\n    dir.create(file.path(\"data\", \"mp01\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nGLOBAL_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"global_top10_alltime.csv\")\n\nif(!file.exists(GLOBAL_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv\", \n                  destfile=GLOBAL_TOP_10_FILENAME)\n}\n\nCOUNTRY_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"country_top10_alltime.csv\")\n\nif(!file.exists(COUNTRY_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv\", \n                  destfile=COUNTRY_TOP_10_FILENAME)\n}"
  },
  {
    "objectID": "mp01.html#acquire-data",
    "href": "mp01.html#acquire-data",
    "title": "Top 10 Netflix Films/Shows",
    "section": "",
    "text": "show/hide code\nif(!dir.exists(file.path(\"data\", \"mp01\"))){\n    dir.create(file.path(\"data\", \"mp01\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nGLOBAL_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"global_top10_alltime.csv\")\n\nif(!file.exists(GLOBAL_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv\", \n                  destfile=GLOBAL_TOP_10_FILENAME)\n}\n\nCOUNTRY_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"country_top10_alltime.csv\")\n\nif(!file.exists(COUNTRY_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv\", \n                  destfile=COUNTRY_TOP_10_FILENAME)\n}"
  },
  {
    "objectID": "mp01.html#data-acquisition",
    "href": "mp01.html#data-acquisition",
    "title": "Top 10 Netflix Films/Shows",
    "section": "Data Acquisition",
    "text": "Data Acquisition\n\n\nshow/hide code\nif(!require(\"tidyverse\")) { install.packages(\"tidyverse\") \n  }\nlibrary(readr) \nlibrary(dplyr) \nGLOBAL_TOP_10 &lt;- read_tsv(GLOBAL_TOP_10_FILENAME)\nglimpse(GLOBAL_TOP_10)\n\n\nRows: 8,880\nColumns: 9\n$ week                       &lt;date&gt; 2025-09-28, 2025-09-28, 2025-09-28, 2025-0…\n$ category                   &lt;chr&gt; \"Films (English)\", \"Films (English)\", \"Film…\n$ weekly_rank                &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, …\n$ show_title                 &lt;chr&gt; \"KPop Demon Hunters\", \"Ruth & Boaz\", \"The W…\n$ season_title               &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"…\n$ weekly_hours_viewed        &lt;dbl&gt; 32200000, 15900000, 13500000, 15700000, 112…\n$ runtime                    &lt;dbl&gt; 1.6667, 1.5500, 1.7833, 2.4333, 1.8333, 1.7…\n$ weekly_views               &lt;dbl&gt; 19300000, 10300000, 7600000, 6500000, 61000…\n$ cumulative_weeks_in_top_10 &lt;dbl&gt; 15, 1, 3, 5, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, …"
  },
  {
    "objectID": "mp01.html#data-cleaning",
    "href": "mp01.html#data-cleaning",
    "title": "Top 10 Netflix Films/Shows",
    "section": "Data cleaning",
    "text": "Data cleaning\n\n\nshow/hide code\nGLOBAL_TOP_10 &lt;- GLOBAL_TOP_10 |&gt; mutate(season_title = if_else(season_title == \"N/A\", NA_character_, season_title))"
  },
  {
    "objectID": "mp01.html#data-importing",
    "href": "mp01.html#data-importing",
    "title": "Top 10 Netflix Films/Shows",
    "section": "Data Importing",
    "text": "Data Importing\n\n\nshow/hide code\nCOUNTRY_TOP_10 &lt;- read_tsv(COUNTRY_TOP_10_FILENAME)\nglimpse(COUNTRY_TOP_10)\n\n\nRows: 413,620\nColumns: 8\n$ country_name               &lt;chr&gt; \"Argentina\", \"Argentina\", \"Argentina\", \"Arg…\n$ country_iso2               &lt;chr&gt; \"AR\", \"AR\", \"AR\", \"AR\", \"AR\", \"AR\", \"AR\", \"…\n$ week                       &lt;date&gt; 2025-09-28, 2025-09-28, 2025-09-28, 2025-0…\n$ category                   &lt;chr&gt; \"Films\", \"Films\", \"Films\", \"Films\", \"Films\"…\n$ weekly_rank                &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, …\n$ show_title                 &lt;chr&gt; \"Sonic the Hedgehog 3\", \"KPop Demon Hunters…\n$ season_title               &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"…\n$ cumulative_weeks_in_top_10 &lt;dbl&gt; 2, 15, 1, 2, 1, 1, 2, 5, 1, 2, 2, 1, 1, 1, …\n\n\n\nData cleaning\n\n\nshow/hide code\nCOUNTRY_TOP_10 &lt;- COUNTRY_TOP_10 |&gt; mutate(season_title = if_else(season_title == \"N/A\", NA_character_, season_title))\n\n\n\n\nData Exploration\n\n\nshow/hide code\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\ninstall.packages(\"DT\")\nlibrary(DT)\nGLOBAL_TOP_10 |&gt; \n    head(n=20) |&gt;\n    datatable(options=list(searching=FALSE, info=FALSE))\n\n\n\n\n\n\nshow/hide code\nlibrary(stringr)\nlibrary(stringr)\nformat_titles &lt;- function(df){\n    colnames(df) &lt;- str_replace_all(colnames(df), \"_\", \" \") |&gt; str_to_title()\n    df\n}\n\nGLOBAL_TOP_10 |&gt; \n    format_titles() |&gt;\n    head(n=20) |&gt;\n    datatable(options=list(searching=FALSE, info=FALSE)) |&gt;\n    formatRound(c('Weekly Hours Viewed', 'Weekly Views'))\n\n\n\n\n\n\nshow/hide code\nGLOBAL_TOP_10 |&gt; \n    select(-season_title) |&gt;\n    format_titles() |&gt;\n    head(n=20) |&gt;\n    datatable(options=list(searching=FALSE, info=FALSE)) |&gt;\n    formatRound(c('Weekly Hours Viewed', 'Weekly Views'))\n\n\n\n\n\n\nshow/hide code\nGLOBAL_TOP_10 |&gt; \n    mutate(`runtime_(minutes)` = round(60 * runtime)) |&gt;\n    select(-season_title, \n           -runtime) |&gt;\n    format_titles() |&gt;\n    head(n=20) |&gt;\n    datatable(options=list(searching=FALSE, info=FALSE)) |&gt;\n    formatRound(c('Weekly Hours Viewed', 'Weekly Views'))\n\n\n\n\n\n\nHow many different countries does Netflix operate in? (You can use the viewing history as a proxy for countries in which Netflix operates.)\n\n\nshow/hide code\nlibrary (dplyr) \nnum_countries &lt;- COUNTRY_TOP_10 %&gt;% summarise(n = n_distinct(country_name))\n\n\nnum_countries 94 countries\nWhich non-English-language film has spent the most cumulative weeks in the global top 10? How many weeks did it spend?\n\n\nshow/hide code\nlibrary (dplyr) \n\ntop_non_english &lt;- GLOBAL_TOP_10 %&gt;% \n  filter (category == \"Films (Non-English)\") %&gt;% arrange (desc(cumulative_weeks_in_top_10)) %&gt;% slice_head(n=1) %&gt;% \nselect(show_title, cumulative_weeks_in_top_10)\n\nprint(top_non_english)\n\n\n# A tibble: 1 × 2\n  show_title                     cumulative_weeks_in_top_10\n  &lt;chr&gt;                                               &lt;dbl&gt;\n1 All Quiet on the Western Front                         23\n\n\nAll Quiet on the Western Front spent 23 weeks in the global 10.\nWhat is the longest film (English or non-English) to have ever appeared in the Netflix global Top 10? How long is it in minutes?\n\n\nshow/hide code\nlibrary(dplyr)\n\nlongest_film &lt;- GLOBAL_TOP_10 %&gt;% filter(grepl (\"Films\",category) &!is.na(runtime)) %&gt;%\ngroup_by(show_title) %&gt;% summarise(max_runtime = max(runtime), .groups = \"drop\") %&gt;% arrange(desc(max_runtime)) %&gt;% slice_head(n = 1)\n\nprint(longest_film)\n\n\n# A tibble: 1 × 2\n  show_title                            max_runtime\n  &lt;chr&gt;                                       &lt;dbl&gt;\n1 Pushpa 2: The Rule (Reloaded Version)        3.73\n\n\nPushpa 2: The Rule (Reloaded Version) with 3.73 hours.\nFor each of the four categories, what program has the most total hours of global viewership?\n\n\nshow/hide code\nlibrary(dplyr) \ntop_programs &lt;- GLOBAL_TOP_10 %&gt;% group_by (category) %&gt;% summarise (total_hours = sum(weekly_hours_viewed,na.rm= TRUE), .groups=\"drop\") %&gt;% slice_max(total_hours, n=1)\n\nprint(top_programs)\n\n\n# A tibble: 1 × 2\n  category     total_hours\n  &lt;chr&gt;              &lt;dbl&gt;\n1 TV (English) 66311130000\n\n\nTV (English) 663,111,30000\nWhich TV show had the longest run in a country’s Top 10? How long was this run and in what country did it occur?\n\n\nshow/hide code\nlibrary(dplyr) \nLongest_run &lt;- COUNTRY_TOP_10 %&gt;% arrange(desc(cumulative_weeks_in_top_10)) %&gt;% slice_head(n=1) %&gt;% select(show_title, cumulative_weeks_in_top_10, country_name)\n\nprint(Longest_run)\n\n\n# A tibble: 1 × 3\n  show_title  cumulative_weeks_in_top_10 country_name\n  &lt;chr&gt;                            &lt;dbl&gt; &lt;chr&gt;       \n1 Money Heist                        127 Pakistan    \n\n\nMoney Heist with 127 min runtime in Pakistan\nNetflix provides over 200 weeks of service history for all but one country in our data set. Which country is this and when did Netflix cease operations in that country?\n\n\nshow/hide code\nlibrary (dplyr) \n\nCOUNTRY_TOP_10 %&gt;% group_by(country_name) %&gt;% \nsummarise( total_weeks = n_distinct(week), last_week = max(week), .groups = \"drop\" ) %&gt;% filter(total_weeks &lt; 200) \n\n\n# A tibble: 1 × 3\n  country_name total_weeks last_week \n  &lt;chr&gt;              &lt;int&gt; &lt;date&gt;    \n1 Russia                35 2022-02-27\n\n\nRussia with 35 weeks and it ceased on 2022-02-27\nThe movie Red Notice has a runtime of 1 hour and 58 minutes. Approximately how many views did it receive in 2021? Note that Netflix does not provide the weekly_views values that far back in the past, but you can compute it yourself using the total view time and the runtime.\n\n\nshow/hide code\nlibrary (dplyr) \nlibrary (lubridate) \n\nruntime_hours &lt;- 1 + 58/60 \nruntime_hours \n\n\n[1] 1.966667\n\n\nshow/hide code\nred_notice_hours &lt;- GLOBAL_TOP_10 %&gt;% \n  filter (show_title == \"Red Notice\", year(week)== 2021) %&gt;% summarise(total_hours = sum(weekly_hours_viewed,na.rm=TRUE))\n\nprint(red_notice_hours)\n\n\n# A tibble: 1 × 1\n  total_hours\n        &lt;dbl&gt;\n1   396740000\n\n\nshow/hide code\ntotal_hours &lt;- red_notice_hours$total_hours\nviews &lt;- total_hours / runtime_hours\n\nviews\n\n\n[1] 201732203\n\n\n201,732,203 runtime hours views.\nHow many Films reached Number 1 in the US but did not originally debut there? That is, find films that first appeared on the Top 10 chart at, e.g., Number 4 but then became more popular and eventually hit Number 1? What is the most recent film to pull this off?\n\n\nshow/hide code\nlibrary (dplyr) \n\nFilms_reached_number_1 &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"united states\", category == \"Films\") %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(\n    first_rank = first(weekly_rank[!is.na(weekly_rank)]),\n    max_rank = min(weekly_rank, na.rm = TRUE),\n    last_week = max(week, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  filter(max_rank == 1 & first_rank != 1) %&gt;%\n  arrange(desc(last_week))\n\nmost_recent_film &lt;-\n  Films_reached_number_1$show_title[1]\n\nprint(Films_reached_number_1)\n\n\n# A tibble: 0 × 4\n# ℹ 4 variables: show_title &lt;chr&gt;, first_rank &lt;dbl&gt;, max_rank &lt;dbl&gt;,\n#   last_week &lt;date&gt;\n\n\nshow/hide code\nprint(most_recent_film)\n\n\n[1] NA\n\n\nNA\nWhich TV show/season hit the top 10 in the most countries in its debut week? In how many countries did it chart?\n\n\nshow/hide code\nlibrary (dplyr) \n\nTop_10_in_most_countries &lt;- COUNTRY_TOP_10 %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(debut_week = min(week, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  left_join(COUNTRY_TOP_10, by = \"show_title\") %&gt;%\n  filter(week == debut_week) %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(countries_count = n_distinct(country_name), .groups = \"drop\") %&gt;%\n  arrange(desc(countries_count))\n\nif (nrow(Top_10_in_most_countries) &gt; 0) {\n  Top_show &lt;- Top_10_in_most_countries %&gt;% slice_head(n = 1)\n  print(Top_show)\n} else {\n  print(\"No data found.\")\n}\n\n\n# A tibble: 1 × 2\n  show_title      countries_count\n  &lt;chr&gt;                     &lt;int&gt;\n1 Army of Thieves              94\n\n\nArmy of Thieves hit the most top 10 in 94 countries"
  },
  {
    "objectID": "mp01.html#vecna-might-have-escaped-but-season-5-will-not",
    "href": "mp01.html#vecna-might-have-escaped-but-season-5-will-not",
    "title": "Top 10 Netflix Films/Shows",
    "section": "Vecna Might Have Escaped… But Season 5 Will Not!",
    "text": "Vecna Might Have Escaped… But Season 5 Will Not!\nNetflix will release the fifth and final season of its hit show Stranger Things at the end of 2025. From exploring the Upside Down and rescuing Will, to saving Max with Running Up That Hill by Kate Bush, Season 5 promises more thrills, chills, and mysteries than ever. Fans will finally uncover more about Eleven’s powers and Papa’s shadowy past. The previous four seasons have captivated viewers worldwide, accumulating 2.9 billion hours of total viewership and remaining in the global Top 10 for 20 weeks.\nStranger Things has also demonstrated remarkable multinational appeal, with previous seasons charting in 93, 91, and 90 countries, making it a true global phenomenon. Compared to other English-language TV shows, it consistently ranks at the top for total viewership and weeks in the Top 10. As fans await Season 5, the series promises to deliver even more excitement, surprises, and unforgettable moments to close out this iconic saga.\n\n\nshow/hide code\nTotal_Viewership &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(show_title == \"Stranger Things\", category == \"TV (English)\") %&gt;%\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))\n\nprint(Total_Viewership)\n\n\n# A tibble: 1 × 1\n  total_hours\n        &lt;dbl&gt;\n1  2967980000\n\n\n\n\nshow/hide code\nLength_of_popularity &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(show_title == \"Stranger Things\", category == \"TV (English)\") %&gt;% \n  summarise(Total_weeks = n_distinct(week))\n\nprint(Length_of_popularity)\n\n\n# A tibble: 1 × 1\n  Total_weeks\n        &lt;int&gt;\n1          20\n\n\n\n\nshow/hide code\nMultinational_appeal &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(show_title == \"Stranger Things\", category == \"TV\") %&gt;%\n  group_by(season_title) %&gt;%\n  summarise(Countries_count = n_distinct(country_name), .groups = \"drop\") %&gt;%\n  arrange(desc(Countries_count))\n\nprint(Multinational_appeal)\n\n\n# A tibble: 4 × 2\n  season_title      Countries_count\n  &lt;chr&gt;                       &lt;int&gt;\n1 Stranger Things 4              93\n2 &lt;NA&gt;                           93\n3 Stranger Things 2              91\n4 Stranger Things 3              90\n\n\n\n\nshow/hide code\nTop_English_TV &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(category == \"TV (English)\") %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(\n    Total_Hours = sum(weekly_hours_viewed, na.rm = TRUE),\n    Total_Weeks = n_distinct(week),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(Total_Hours))\n\nprint(Top_English_TV)\n\n\n# A tibble: 515 × 3\n   show_title      Total_Hours Total_Weeks\n   &lt;chr&gt;                 &lt;dbl&gt;       &lt;int&gt;\n 1 Stranger Things  2967980000          20\n 2 Wednesday        2876350000          29\n 3 Bridgerton       2279710000          26\n 4 Ginny & Georgia  1556880000          13\n 5 You              1542990000          20\n 6 Manifest         1320520000          29\n 7 Love Is Blind    1311300000          37\n 8 The Night Agent  1307720000          18\n 9 Outer Banks      1275610000          20\n10 Virgin River     1135110000          24\n# ℹ 505 more rows"
  },
  {
    "objectID": "mp01.html#bollywood-is-growing",
    "href": "mp01.html#bollywood-is-growing",
    "title": "Top 10 Netflix Films/Shows",
    "section": "Bollywood is Growing!",
    "text": "Bollywood is Growing!\nBollywood has become increasingly popular over the years, gaining more views for their shows while also adding international content. Popular global hits like Money Heist, Squid Game, and Wednesday stayed in India’s top 10 for more than 35 weeks, demonstrating strong engagement. Assuming that each top-10 Hindi show accounts for approximately 10,000 hours of viewing per week, Netflix estimates a total of 6.5 million of hours viewed across the top Hindi shows, translating to roughly 164 thousand of estimated users.\nIndia has also seen unique local hits that did not chart in the U.S., including films like Kantara, Hi Papa, and Sir. These shows highlight the distinct preferences of the Indian audience and reinforce the long-term growth potential for Netflix in this populated market. With consistent engagement from both Hindi-language content and popular international shows, India represents a major opportunity for continued subscriber growth.\n\n\nshow/hide code\nlibrary(dplyr)\nIndia_Content &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"India\") %&gt;%\n  group_by(show_title, category) %&gt;%\n  summarise(\n    Total_Weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(Total_Weeks))\n\nhead(India_Content, 10)\n\n\n# A tibble: 10 × 3\n   show_title                                        category Total_Weeks\n   &lt;chr&gt;                                             &lt;chr&gt;          &lt;dbl&gt;\n 1 Money Heist                                       TV                48\n 2 Squid Game                                        TV                43\n 3 Wednesday                                         TV                36\n 4 The Railway Men - The Untold Story Of Bhopal 1984 TV                30\n 5 Khakee: The Bihar Chapter                         TV                29\n 6 All of Us Are Dead                                TV                28\n 7 Maamla Legal Hai                                  TV                26\n 8 RRR (Hindi)                                       Films             25\n 9 Haseen Dillruba                                   Films             21\n10 Stranger Things                                   TV                21\n\n\n\n\nshow/hide code\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(dplyr)\nlibrary(stringr)\n\nHindi_Content &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"India\", str_detect(show_title, \"\\\\(Hindi\\\\)\"))\n\n\nhours_per_week_per_show &lt;- 10000\n\nHindi_Customers &lt;- Hindi_Content %&gt;%\n  summarise(\n    Total_Hours = sum(cumulative_weeks_in_top_10 * hours_per_week_per_show, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n\n    Estimated_Users = Total_Hours / (4 * 10)\n  )\n\nHindi_Customers\n\n\n# A tibble: 1 × 2\n  Total_Hours Estimated_Users\n        &lt;dbl&gt;           &lt;dbl&gt;\n1     6580000          164500\n\n\n\n\nshow/hide code\nlibrary(dplyr)\nIndia_Hindi &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"India\", str_detect(show_title, \"\\\\(Hindi\\\\)\")) %&gt;%\n  select(show_title, category, weekly_rank, cumulative_weeks_in_top_10)\n\n\nUS_Shows &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"United States\") %&gt;%\n  pull(show_title) %&gt;%\n  unique()\n\nIndia_only_Hindi &lt;- India_Hindi %&gt;%\n  filter(!show_title %in% US_Shows) %&gt;%\n  arrange(desc(cumulative_weeks_in_top_10))\n\nhead(India_only_Hindi, 10)\n\n\n# A tibble: 10 × 4\n   show_title      category weekly_rank cumulative_weeks_in_top_10\n   &lt;chr&gt;           &lt;chr&gt;          &lt;dbl&gt;                      &lt;dbl&gt;\n 1 Kantara (Hindi) Films             10                         11\n 2 Kantara (Hindi) Films             10                         10\n 3 Kantara (Hindi) Films             10                          9\n 4 Kantara (Hindi) Films              6                          8\n 5 Hi Papa (Hindi) Films              8                          7\n 6 Sir (Hindi)     Films              6                          7\n 7 Kantara (Hindi) Films              7                          7\n 8 Leo (Hindi)     Films              9                          6\n 9 Hi Papa (Hindi) Films              9                          6\n10 Sir (Hindi)     Films              8                          6"
  },
  {
    "objectID": "mp01.html#east-asian-shows-and-their-growth-in-netflix.",
    "href": "mp01.html#east-asian-shows-and-their-growth-in-netflix.",
    "title": "Top 10 Netflix Films/Shows",
    "section": "East Asian shows and their growth in Netflix.",
    "text": "East Asian shows and their growth in Netflix.\nNetflix is gaining a global popularity Content on East Asia with shows and films, from Korea, Japan, China, Taiwan and Thailand. Thailand leads the region with 8 distinct titles topping local charts for a combined 129 weeks, followed by Hong Kong (4 shows, 24 weeks) and Singapore (3 shows, 5 weeks). Standout hits include MasterChef The Professionals Thailand (45 weeks), The Face Thailand (36 weeks), and The Voice Thailand 2024 (36 weeks). Many shows, such as Strange Frequencies: Taiwan Killer Hospital and A Korean Odyssey, have charted in multiple countries, highlighting the broad international appeal of East Asian shows.\nThese shows are also gaining traction in the Americas and other global markets, signaling strong opportunities for subscriber growth. Netflix’s investment in East Asian content demonstrates its commitment to offering culturally relevant programming that resonates worldwide. With audiences increasingly seeking international content, these titles represent both current success and long-term growth potential for Netflix across multiple regions.\n\n\nshow/hide code\nlibrary(dplyr)\nlibrary(stringr)\nEastAsia_Shows &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(str_detect(show_title, regex(\"Korean|Japanese|Chinese|Taiwan|Thailand\", ignore_case = TRUE)))\n\n\nShows_per_Country &lt;- EastAsia_Shows %&gt;%\n  group_by(country_name) %&gt;%\n  summarise(\n    Num_Shows = n_distinct(show_title),\n    Total_Weeks = sum(cumulative_weeks_in_top_10, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(Num_Shows))\n\nprint(Shows_per_Country)\n\n\n# A tibble: 13 × 3\n   country_name Num_Shows Total_Weeks\n   &lt;chr&gt;            &lt;int&gt;       &lt;dbl&gt;\n 1 Thailand             8         129\n 2 Hong Kong            4          24\n 3 Singapore            3           5\n 4 Egypt                2           4\n 5 Malaysia             2           6\n 6 South Korea          2           4\n 7 Vietnam              2           2\n 8 Indonesia            1           1\n 9 Kenya                1           3\n10 Mauritius            1           3\n11 Nigeria              1           1\n12 Philippines          1           6\n13 South Africa         1           1\n\n\nshow/hide code\nTop_Shows_Global &lt;- EastAsia_Shows %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(\n    Total_Weeks_Global = sum(cumulative_weeks_in_top_10, na.rm = TRUE),\n    Countries = n_distinct(country_name),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(Total_Weeks_Global))\n\nprint(Top_Shows_Global)\n\n\n# A tibble: 15 × 3\n   show_title                                      Total_Weeks_Global Countries\n   &lt;chr&gt;                                                        &lt;dbl&gt;     &lt;int&gt;\n 1 MasterChef The Professionals Thailand                           45         1\n 2 The Face Thailand                                               36         1\n 3 The Voice Thailand 2024                                         36         1\n 4 A Korean Odyssey                                                24         2\n 5 Strange Frequencies: Taiwan Killer Hospital                     14         5\n 6 Chinese Zodiac                                                   8         4\n 7 The Restaurant War Thailand                                      6         1\n 8 Junji Ito Maniac: Japanese Tales of the Macabre                  5         3\n 9 Korean Fried Chicken Rhapsody                                    5         3\n10 Risqué Business: Taiwan                                          3         3\n11 The Great Chinese Beans                                          3         1\n12 Hell's Kitchen Thailand                                          1         1\n13 Iron Chef Thailand VS Asia                                       1         1\n14 O La Nor I Love Thailand                                         1         1\n15 Thieves in Thailand                                              1         1"
  }
]